name: Test - AITs

on:
  workflow_dispatch:
    inputs:
      agent-ref:
        description: "Specify agent branch/tag/sha (main is default)"
        required: false
        default: 'main'
      ait-ref:
        description: "Specify AIT branch/tag/sha (main is default)"
        required: false
        default: 'main'
      cache-ref:
        description: "Specify cache branch/tag/sha (main is default)"
        required: false
        default: 'main'
      single-test:
        description: "Specify a single test. If left blank, all tests will run. You can choose to specify a single test file or a test case in that file. For example you can write 'server/tomcat.py' to run all tomcat tests or run 'server/tomcat.py TomcatTest.test_tomcat' to run a specific test case."
        required: false
        default: ''
      wiki-report-desc:
        description: "(Optional) Description for wiki reports (used when publishing ingest metrics and/or metrics summary.) NO SPACES. Ex: Release9.0.0"
        required: false
      publish-ingest-metrics:
        description: "Publish ingest metrics to wiki"
        required: false
        default: false
        type: boolean
      publish-ait-performance:
        description: "Publish AIT performance metrics to wiki"
        required: false
        default: false
        type: boolean
  workflow_call:
    inputs:
      agent-ref:
        description: "Specify agent branch/tag/sha (main is default)"
        required: false
        default: 'main'
        type: string
      ait-ref:
        description: "Specify AIT branch/tag/sha (main is default)"
        required: false
        default: 'main'
        type: string
      cache-ref:
        description: "Specify cache branch/tag/sha (main is default)"
        required: false
        default: 'main'
        type: string
      single-test:
        description: "Specify a single test. If left blank, all tests will run. You can choose to specify a single test file or a test case in that file. For example you can write 'server/tomcat.py' to run all tomcat tests or run 'server/tomcat.py TomcatTest.test_tomcat' to run a specific test case."
        required: false
        default: ''
        type: string
      wiki-report-desc:
        description: "(Optional) Description for wiki reports (used when publishing ingest metrics and/or metrics summary.) NO SPACES. Ex: Release9.0.0"
        required: false
        type: string
      publish-ingest-metrics:
        description: "Publish ingest metrics to wiki"
        required: false
        default: false
        type: boolean
      publish-ait-performance:
        description: "Publish AIT performance metrics to wiki"
        required: false
        default: false
        type: boolean

jobs:
  build-agent:
    uses: ./.github/workflows/X-Reusable-BuildAgent.yml
    with:
      # inputs.agent-ref is for workflow dispatch/call, github.ref for PR or push, main if all else fail
      agent-ref: ${{ inputs.agent-ref || github.ref || 'main' }}
    secrets: inherit

  list-tests:
    name: List tests
    runs-on: ubuntu-22.04
    outputs:
      tests: ${{ steps.read-single-test.outputs.tests || steps.read-tests.outputs.tests }}
    steps:
      - name: Checkout AIT repo test
        uses: actions/checkout@0ad4b8fadaa221de15dcec353f45205ec38ea70b # pin@v4
        with:
          repository: newrelic/java-agent-integration-tests
          ref: ${{ inputs.ait-ref || 'main' }}
          token: ${{ secrets.AITPAT }}
          path: agent-integration-tests

      - id: read-tests
        name: List instrumentation tests
        if: ${{inputs.single-test == ''}}
        run: |
          excluded_tests=$(mktemp /tmp/excluded_tests.XXXXXXXX)
          echo "framework/pekko/pekko.py" >> $excluded_tests
          echo "framework/pekko/pekkohttp.py" >> $excluded_tests
          echo "framework/pekko/pekkohttp3.py" >> $excluded_tests
          echo "datastore/datastores.py" >> $excluded_tests
          echo "framework/jms/jms.py" >> $excluded_tests
          echo "r2dbc/mssql.py" >> $excluded_tests
          echo "server/mule.py" >> $excluded_tests
          echo "server/weblogic.py" >> $excluded_tests
          echo "basic_features/inf_tracing_test.py" >> $excluded_tests
          echo "security/lasp_msg_params.py" >> $excluded_tests
          # The files below are not tests
          echo "trace/client.py" >> $excluded_tests
          echo "trace/server.py" >> $excluded_tests
          echo "trace/trace_base.py" >> $excluded_tests
          echo "trace/tracecontext/__init__.py" >> $excluded_tests
          echo "trace/tracecontext/traceparent.py" >> $excluded_tests
          echo "trace/tracecontext/tracestate.py" >> $excluded_tests
          cd agent-integration-tests/tests/java/functionality
          tmpfile=$(mktemp /tmp/dirs.XXXXXXXXXX)
          # list the tests
          find . -iname "*.py" | cut -d'/' -f 2- | grep -v -x -f $excluded_tests | sort > $tmpfile
          # checking if there is at least one test, xargs trims the output
          TEST_COUNT=$(cat $tmpfile | wc -l | xargs)
          if [[ "$TEST_COUNT" == "0" ]];
          then
            echo ":x: Failure: no test was found. There is probably something wrong with the script." >>$GITHUB_STEP_SUMMARY
            exit 1
          fi
          # converting the simple test list to a JSON array
          FILES=$(cat $tmpfile | jq -R -s -c 'split("\n")[:-1]')
          # creates an envar with the ait files in a JSON format
          TESTS=$((
            echo '{ "tests" : '
            echo $FILES
            echo " }"
          ) | jq -c .)
          # save the output of the job
          echo "tests=$TESTS" >> $GITHUB_OUTPUT

      - id: read-single-test
        name: Read single test
        if: ${{inputs.single-test != ''}}
        run: |
          # creates an envar with a single test in the same JSON format as the read-tests step above
          TESTS=$((
            echo '{ "tests" : '
            echo ' ["${{ inputs.single-test }}"] ' 
            echo " }"
          ) | jq -c .)
          # save the output of the job
          echo "tests=$TESTS" >> $GITHUB_OUTPUT

  tests:
    name: ${{ matrix.tests }}
    needs: [ build-agent, list-tests ]
    timeout-minutes: 120
    runs-on: ubuntu-22.04
    # Determine if easier to make the env strings below part of the matrix
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.list-tests.outputs.tests) }}
    steps:
      - name: Retrieve agent from cache
        id: retrieve-agent
        uses: actions/cache@1bd1e32a3bdc45362d1e726936510720a7c30a57 # pin@v4.2.0 # pin@v4
        with:
          path: /home/runner/work/newrelic-java-agent/newrelic-java-agent/newrelic-agent/build/newrelicJar/newrelic.jar
          key: agent-jar-${{ github.run_id }}
          fail-on-cache-miss: true

      ## Ongoing tests with artifactory dependencies
      - name: Checkout AIT repo test
        uses: actions/checkout@0ad4b8fadaa221de15dcec353f45205ec38ea70b # pin@v4
        with:
          repository: newrelic/java-agent-integration-tests
          ref: ${{ inputs.ait-ref }}
          token: ${{ secrets.AITPAT }}
          path: agent-integration-tests

      # Apps repos/caches - this process could be a candidate for custom action
      - name: Checkout Cache 1
        uses: actions/checkout@0ad4b8fadaa221de15dcec353f45205ec38ea70b # pin@v4
        with:
          repository: newrelic/java-ait-cache-1
          ref: ${{ inputs.cache-ref || 'main' }}
          token: ${{ secrets.AITPAT }}
          path: appcache1
          lfs: true

      - name: Checkout Cache 2
        uses: actions/checkout@0ad4b8fadaa221de15dcec353f45205ec38ea70b # pin@v4
        with:
          repository: newrelic/java-ait-cache-2
          ref: ${{ inputs.cache-ref || 'main' }}
          token: ${{ secrets.AITPAT }}
          path: appcache2
          lfs: true

      - name: Checkout Cache 3
        uses: actions/checkout@0ad4b8fadaa221de15dcec353f45205ec38ea70b # pin@v4
        with:
          repository: newrelic/java-ait-cache-3
          ref: ${{ inputs.cache-ref || 'main' }}
          token: ${{ secrets.AITPAT }}
          path: appcache3
          lfs: true

      - name: Checkout Cache 4
        uses: actions/checkout@0ad4b8fadaa221de15dcec353f45205ec38ea70b # pin@v4
        with:
          repository: newrelic/java-ait-cache-4
          ref: ${{ inputs.cache-ref || 'main' }}
          token: ${{ secrets.AITPAT }}
          path: appcache4
          lfs: true

      - name: Checkout Cache 5
        uses: actions/checkout@0ad4b8fadaa221de15dcec353f45205ec38ea70b # pin@v4
        with:
          repository: newrelic/java-ait-cache-5
          ref: ${{ inputs.cache-ref || 'main' }}
          token: ${{ secrets.AITPAT }}
          path: appcache5
          lfs: true

      # Consolidate caches into one directory
      - name: Consolidate caches into Apps directory
        run: |
          mkdir apps
          mv appcache1/* apps/
          mv appcache2/* apps/
          mv appcache3/* apps/
          mv appcache4/* apps/

      # looks like docker is not properly sanitized between runs in GHA
      # so its disk space may be pilling up and blows up during our tests
      # other cleanups were suggested on runner-images repo
      - name: Clean up disk
        run: |
          docker images -q | xargs -r docker rmi
          sudo apt clean
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /opt/ghc

      ## JDK Installs

      # Install Zulu
      - name: Set up Zulu versions
        uses: actions/setup-java@99b8673ff64fbf99d8d325f52d9a5bdedb8483e9 # pin@v4
        with:
          distribution: 'zulu'
          java-version: |
            25
            21
            17
            11

      # Set the JDK variables for Zulu
      - name: Set the JDK variables for Zulu
        run: |
          echo "JDK_zulu_11=${JAVA_HOME_11_X64}" >> $GITHUB_ENV
          echo "JDK_zulu_17=${JAVA_HOME_17_X64}" >> $GITHUB_ENV
          echo "JDK_zulu_21=${JAVA_HOME_21_X64}" >> $GITHUB_ENV
          echo "JDK_zulu_25=${JAVA_HOME_25_X64}" >> $GITHUB_ENV

      - name: Set up Javas
        uses: actions/setup-java@99b8673ff64fbf99d8d325f52d9a5bdedb8483e9 # pin@v4
        with:
          distribution: 'temurin'
          java-version: |
            25
            21
            17
            11
            8

      - name: Set up Toolchain
        shell: bash
        run: |
          mkdir -p $HOME/.m2 \
          && cat << EOF > $HOME/.m2/toolchains.xml
          <?xml version="1.0" encoding="UTF8"?>
          <!-- toolchains.xml is used by the pom in the Java11_test_webapp.  -->
          <toolchains>
            <toolchain>
            <type>jdk</type>
            <provides>
                    <version>8</version>
            </provides>
            <configuration>
                    <jdkHome>${JAVA_HOME_8_X64}</jdkHome>
            </configuration>
            </toolchain>
            <toolchain>
            <type>jdk</type>
            <provides>
                    <version>11</version>
            </provides>
            <configuration>
                    <jdkHome>${JAVA_HOME_11_X64}</jdkHome>
            </configuration>
            </toolchain>
            <toolchain>
            <type>jdk</type>
            <provides>
                    <version>17</version>
            </provides>
            <configuration>
                    <jdkHome>${JAVA_HOME_17_X64}</jdkHome>
            </configuration>
            </toolchain>
            <toolchain>
            <type>jdk</type>
            <provides>
                    <version>21</version>
            </provides>
            <configuration>
                    <jdkHome>${JAVA_HOME_21_X64}</jdkHome>
            </configuration>
            </toolchain>
          <toolchain>
            <type>jdk</type>
            <provides>
                    <version>25</version>
            </provides>
            <configuration>
                    <jdkHome>${JAVA_HOME_25_X64}</jdkHome>
            </configuration>
            </toolchain>
          </toolchains>
          EOF

      ## End JDK Install

      ## TESTING SECTION

      # Replication of steps from ait README

      - name: CD to agent-integration-tests dir.
        run: cd agent-integration-tests/

      - name: Set Test Name Env Var
        run: |
          TEST_NAME=$(echo ${{ matrix.tests }} | sed 's|/|-|g')
          echo "TEST_NAME="${TEST_NAME}"" >> $GITHUB_ENV

      - name: Fix the /etc/hosts/ file (since it's been messed up before)
        run: |
          echo "Old /etc/hosts/ file"
          cat /etc/hosts
          echo "Overwriting /etc/hosts file"
          sudo echo "127.0.0.1 localhost $HOSTNAME" | sudo tee /etc/hosts
          echo "New /etc/hosts file"
          cat /etc/hosts

      ## WE LOSE THE VIRTUAL ENVIRONMENT ONCE WE LEAVE THE STEP
      ## TODO: This should really be a custom action, too many commands
      - name: Create virtualenv and run ${{ matrix.tests }}
        if: ${{ failure() || success() }}
        run: |
          cd agent-integration-tests
          echo "conf/testenv complains of the path below - creating symlink for now"
          ln -s ${GITHUB_WORKSPACE}/apps /home/runner/apps
          ln -s ${GITHUB_WORKSPACE}/newrelic-agent/build/newrelicJar/newrelic.jar ${GITHUB_WORKSPACE}/newrelic.jar
          echo "still complains of file not found"
          sudo apt-get install virtualenv
          virtualenv -p /usr/bin/python3.10 .
          . bin/activate
          bin/pip3 install -r conf/requirements.txt
          ZULU11=${JDK_zulu_11} \
          ZULU17=${JDK_zulu_17} \
          ZULU21=${JDK_zulu_21} \
          ZULU25=${JDK_zulu_25} \
          JAVA8JRE=${JAVA_HOME_8_X64} \
          JAVA11JRE=${JAVA_HOME_11_X64} \
          JAVA17JRE=${JAVA_HOME_17_X64} \
          JAVA21JRE=${JAVA_HOME_21_X64} \
          JAVA25JRE=${JAVA_HOME_25_X64} \
          conf/autoconfigure
          . conf/testenv java
          cat conf/java_local_config.yml
          sed -i 's|java_agent_dev_root: /home/runner/work/newrelic-java-agent/newrelic-java-agent|java_agent_dev_root: /home/runner/work/newrelic-java-agent/newrelic-java-agent/newrelic-agent/build/newrelicJar|' conf/java_local_config.yml
          sed -i 's|app_root: /home/runner/apps|app_root: /home/runner/work/newrelic-java-agent/newrelic-java-agent/apps|' conf/java_local_config.yml
          ## artifacts section for testing
          mkdir testing-artifacts
          touch testing-artifacts/shell-variables.txt
          touch testing-artifacts/env-variables.txt
          set | sort -f > testing-artifacts/shell-variables.txt
          printenv | sort -f > testing-artifacts/env-variables.txt
          cp conf/java_local_config.yml testing-artifacts/
          ## End testing artifacts section
          TEST_LOG_LEVEL=DEBUG TEST_SUPPRESS_METRIC_DEBUG=1 \
          PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python \
          ./bin/runtest.sh tests/java/functionality/${{ matrix.tests }}

      - name: Export Test Name
        if: ${{ always() }}
        run: |
          TEST_NAME=$(echo ${{ matrix.tests }} | sed 's|/|-|g')
          echo "TEST_NAME=${TEST_NAME}" >> $GITHUB_ENV

      # Rename matrix item to remove problem characters
      - name: Rename Matrix item
        run: |
          MATRIX_ITEM=$(echo ${{ matrix.tests }} | sed 's|/|-|g')
          echo "MATRIX="${MATRIX_ITEM}"" >> $GITHUB_ENV

      - name: Capture testing artifacts
        if: ${{ failure() || success() }}
        uses: actions/upload-artifact@65462800fd760344b1a7b4382951275a0abb4808 # pin@v4
        with:
          name: ${{ github.workflow }}-${{ github.job }}-${{ env.MATRIX }}
          path: |
            agent-integration-tests/testing-artifacts/*

      - name: Upload negative value artifact
        uses: actions/upload-artifact@65462800fd760344b1a7b4382951275a0abb4808 # pin@v4
        with:
          path: ${{ github.workspace }}/negative_value_*.txt
          if-no-files-found: ignore

      - name: Upload raw ingest metric files
        if: ${{ success() && inputs.wiki-report-desc != '' && inputs.publish-ingest-metrics }}
        uses: actions/upload-artifact@65462800fd760344b1a7b4382951275a0abb4808 # pin@v4
        with:
          name: ingest-raw-data-${{ env.MATRIX }}
          path: ${{ github.workspace }}/ingest-*.txt
          if-no-files-found: ignore

      - name: Upload AIT performance files
        if: ${{ success() && inputs.wiki-report-desc != '' && inputs.publish-ait-performance }}
        uses: actions/upload-artifact@65462800fd760344b1a7b4382951275a0abb4808 # pin@v4
        with:
          name: ait-performance-${{ env.MATRIX }}
          path: ${{ github.workspace }}/*-metrics-summary.json
          if-no-files-found: ignore

  process-ingest-metric-files:
    name: Process Ingest Metrics
    needs: [ tests ]
    if: ${{ always() && inputs.wiki-report-desc != '' && inputs.publish-ingest-metrics }}
    runs-on: ubuntu-22.04
    permissions:
      contents: write

    steps:
      - name: Download all raw ingest files
        uses: actions/download-artifact@65a9edc5881444af0b9093a5e628f2fe47ea3b2e # pin@v4
        with:
          pattern: ingest-raw-data-*
          merge-multiple: true
          path: all-ingest-files

      - name: "Aggregate and sum all files"
        run: |
          # Check if directory exists and has files
          if [ ! -d "all-ingest-files" ] || [ -z "$(ls -A all-ingest-files 2>/dev/null)" ]; then
            echo "No ingest files found to process"
            echo "## Ingest across all tests: 0" >> $GITHUB_STEP_SUMMARY
            # Create empty files for downstream steps
            echo "" > ingest-aggregate.txt
            echo "0" > ingest-sum.txt
            exit 0
          fi

          cd all-ingest-files

          # Check if any files were actually downloaded
          # 'shopt -s nullglob' makes the glob expand to nothing if no files match
          shopt -s nullglob
          files=(ingest-*.txt)

          echo "Creating single aggregate ingest metric file.."
          cat ingest-*.txt > ../ingest-aggregate.txt

          echo "Summing bytes sent across the full test run.."
          cat ingest-*.txt | awk -F'/' '/BytesSent/ { sum += $5 } END { if (sum == "") sum = 0; print sum }' > ../ingest-sum.txt
          cat ../ingest-sum.txt

          # Write total to summary page
          TOTAL_SUM=$(cat ../ingest-sum.txt)
          echo "## Ingest across all tests: $TOTAL_SUM" >> $GITHUB_STEP_SUMMARY

      - name: Upload processed artifacts
        uses: actions/upload-artifact@65462800fd760344b1a7b4382951275a0abb4808 # pin@v4
        with:
          name: processed-ingest-files
          path: |
            ingest-aggregate.txt
            ingest-sum.txt
          if-no-files-found: ignore

      - name: Create markdown file
        if: ${{ inputs.wiki-report-desc != '' }}
        run: |
          # Start with the sum as the first line
          echo "# Ingest Metrics Summary - ${{ inputs.wiki-report-desc }}" > ingest-report.md
          echo "" >> ingest-report.md
          echo "## **Total Bytes Sent:** $(cat ingest-sum.txt)" >> ingest-report.md
          echo "" >> ingest-report.md
          echo "---" >> ingest-report.md
          echo "" >> ingest-report.md
          echo "### Detailed Metrics" >> ingest-report.md
          echo "" >> ingest-report.md
          echo "\`\`\`" >> ingest-report.md
          cat ingest-aggregate.txt >> ingest-report.md
          echo "\`\`\`" >> ingest-report.md

      - name: Checkout wiki repository
        if: ${{ inputs.wiki-report-desc != '' }}
        uses: actions/checkout@0ad4b8fadaa221de15dcec353f45205ec38ea70b # pin@v4
        with:
          repository: ${{ github.repository }}.wiki
          path: wiki

      - name: Commit and push to wiki
        if: ${{ inputs.wiki-report-desc != '' }}
        run: |
          # Create ingest-metrics directory if it doesn't exist
          mkdir -p wiki/ingest-metrics

          # Copy the report using ingest-metrics-desc as filename
          FILENAME="ingest-metrics-${{ inputs.wiki-report-desc }}.md"
          cp ingest-report.md "wiki/ingest-metrics/${FILENAME}"

          cd wiki

          # Append link to Ingest-Metrics.md if it doesn't already exist
          LINK_TEXT="- [Ingest Metrics ${{ inputs.wiki-report-desc }}](https://github.com/${{ github.repository }}/wiki/ingest-metrics-${{ inputs.wiki-report-desc }})"
          if ! grep -q "ingest-metrics-${{ inputs.wiki-report-desc }})" Ingest-Metrics.md 2>/dev/null; then
            echo "" >> Ingest-Metrics.md
            echo "${LINK_TEXT}" >> Ingest-Metrics.md
          fi

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add "ingest-metrics/${FILENAME}" Ingest-Metrics.md
          git commit -m "Update ingest metrics report for ${{ inputs.wiki-report-desc }} from workflow run ${{ github.run_id }}"
          git push

  process-ait-performance:
    name: Process AIT Performance Metrics
    needs: [ tests ]
    if: ${{ always() && inputs.wiki-report-desc != '' && inputs.publish-ait-performance }}
    runs-on: ubuntu-22.04
    permissions:
      contents: write

    steps:
      - name: Download all AIT performance files
        uses: actions/download-artifact@65a9edc5881444af0b9093a5e628f2fe47ea3b2e # pin@v4
        with:
          pattern: ait-performance-*
          merge-multiple: true
          path: all-ait-performance

      - name: Create AIT performance markdown report
        run: |
          echo "# AIT Performance Metrics - ${{ inputs.wiki-report-desc }}" > ait-performance-report.md
          echo "" >> ait-performance-report.md
          echo "Generated: $(date)" >> ait-performance-report.md
          echo "" >> ait-performance-report.md

          # Create temporary file for storing parsed data
          TEMP_FILE=$(mktemp)

          # Process each JSON file (JSONL format - one JSON object per line)
          for file in all-ait-performance/*-metrics-summary.json; do
            if [ -f "$file" ]; then
              while IFS= read -r test_result; do
                [ -z "$test_result" ] && continue

                TEST_NAME=$(echo "$test_result" | jq -r '.metadata.test_name')
                JAVA_VERSION=$(echo "$test_result" | jq -r '.metadata.java_version')

                # Parse test name for hierarchy: <dir>-<test_file>.<test_case>
                DIR=$(echo "$TEST_NAME" | cut -d'-' -f1)
                REST=$(echo "$TEST_NAME" | cut -d'-' -f2-)
                TEST_FILE=$(echo "$REST" | cut -d'.' -f1)
                TEST_CASE=$(echo "$REST" | cut -d'.' -f2-)

                # Store: dir|test_file|test_case|test_name|java_version|json_data
                echo "${DIR}|${TEST_FILE}|${TEST_CASE}|${TEST_NAME}|${JAVA_VERSION}|${test_result}" >> "$TEMP_FILE"
              done < "$file"
            fi
          done

          # Sort by dir, test_file, test_case, java_version
          sort "$TEMP_FILE" -o "$TEMP_FILE"

          # Helper functions for closing nested dropdowns
          close_test_case() {
            if [ -n "$CURRENT_TEST_CASE" ]; then
              echo "" >> ait-performance-report.md
              echo "</details>" >> ait-performance-report.md
              echo "</blockquote>" >> ait-performance-report.md
              echo "</blockquote>" >> ait-performance-report.md
              echo "" >> ait-performance-report.md
            fi
          }

          close_test_file() {
            if [ -n "$CURRENT_TEST_FILE" ]; then
              echo "" >> ait-performance-report.md
              echo "</details>" >> ait-performance-report.md
              echo "</blockquote>" >> ait-performance-report.md
              echo "" >> ait-performance-report.md
            fi
          }

          close_directory() {
            if [ -n "$CURRENT_DIR" ]; then
              echo "" >> ait-performance-report.md
              echo "</details>" >> ait-performance-report.md
              echo "" >> ait-performance-report.md
            fi
          }

          # Track current context for nested dropdowns
          CURRENT_DIR=""
          CURRENT_TEST_FILE=""
          CURRENT_TEST_CASE=""

          while IFS='|' read -r DIR TEST_FILE TEST_CASE TEST_NAME JAVA_VERSION JSON_DATA; do
            # Open new directory dropdown if changed
            if [ "$DIR" != "$CURRENT_DIR" ]; then
              close_test_case
              close_test_file
              close_directory

              echo "<details>" >> ait-performance-report.md
              echo "<summary><strong>üìÅ ${DIR}</strong></summary>" >> ait-performance-report.md
              echo "" >> ait-performance-report.md
              CURRENT_DIR="$DIR"
              CURRENT_TEST_FILE=""
              CURRENT_TEST_CASE=""
            fi

            # Open new test file dropdown if changed
            if [ "$TEST_FILE" != "$CURRENT_TEST_FILE" ]; then
              close_test_case
              close_test_file

              echo "<blockquote>" >> ait-performance-report.md
              echo "<details>" >> ait-performance-report.md
              echo "<summary><strong>üìÑ ${TEST_FILE}</strong></summary>" >> ait-performance-report.md
              echo "" >> ait-performance-report.md
              CURRENT_TEST_FILE="$TEST_FILE"
              CURRENT_TEST_CASE=""
            fi

            # Open new test case dropdown if changed
            if [ "$TEST_CASE" != "$CURRENT_TEST_CASE" ]; then
              close_test_case

              echo "<blockquote>" >> ait-performance-report.md
              echo "<details>" >> ait-performance-report.md
              echo "<summary><strong>üìã ${TEST_NAME}</strong></summary>" >> ait-performance-report.md
              echo "" >> ait-performance-report.md
              CURRENT_TEST_CASE="$TEST_CASE"
            fi
          
            # Add metrics table directly
            CPU_TIME=$(echo "$JSON_DATA" | jq -r '.metrics.cpu_time')
            RESP_TIME=$(echo "$JSON_DATA" | jq -r '.metrics.response_time_total')
            RESP_COUNT=$(echo "$JSON_DATA" | jq -r '.metrics.response_count')
            THROUGHPUT=$(echo "$JSON_DATA" | jq -r '.metrics.throughput')
            ERROR_COUNT=$(echo "$JSON_DATA" | jq -r '.metrics.error_count')
            HEAP_PRESENT=$(echo "$JSON_DATA" | jq -r '.metrics.heap_metrics_present')

            echo "" >> ait-performance-report.md
            echo "| Metric | Value |" >> ait-performance-report.md
            echo "|--------|-------|" >> ait-performance-report.md
            echo "| Java Version | ${JAVA_VERSION} |" >> ait-performance-report.md
            echo "| CPU Time (s) | ${CPU_TIME} |" >> ait-performance-report.md
            echo "| Response Time Total (s) | ${RESP_TIME} |" >> ait-performance-report.md
            echo "| Response Count | ${RESP_COUNT} |" >> ait-performance-report.md
            echo "| Throughput | ${THROUGHPUT} |" >> ait-performance-report.md
            echo "| Error Count | ${ERROR_COUNT} |" >> ait-performance-report.md

            if [ "$HEAP_PRESENT" = "true" ]; then
              echo "| Heap Utilization Max (%) | ${HEAP_UTIL} |" >> ait-performance-report.md
              echo "| Heap Used Bytes Max | ${HEAP_USED} |" >> ait-performance-report.md
            fi
            echo "" >> ait-performance-report.md
          done < "$TEMP_FILE"

          # Close final nested dropdowns
          close_test_case
          close_test_file
          close_directory

          rm -f "$TEMP_FILE"

      - name: Checkout wiki repository
        uses: actions/checkout@0ad4b8fadaa221de15dcec353f45205ec38ea70b # pin@v4
        with:
          repository: ${{ github.repository }}.wiki
          path: wiki

      - name: Commit and push to wiki
        run: |
          mkdir -p wiki/ait-performance

          FILENAME="ait-performance-${{ inputs.wiki-report-desc }}.md"
          cp ait-performance-report.md "wiki/ait-performance/${FILENAME}"

          cd wiki

          # Add link to index page
          LINK_TEXT="- [AIT Performance ${{ inputs.wiki-report-desc }}](https://github.com/${{ github.repository }}/wiki/ait-performance-${{ inputs.wiki-report-desc }})"
          if ! grep -q "ait-performance-${{ inputs.wiki-report-desc }})" AIT-Performance.md 2>/dev/null; then
            echo "" >> AIT-Performance.md
            echo "${LINK_TEXT}" >> AIT-Performance.md
          fi

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add "ait-performance/${FILENAME}" AIT-Performance.md
          git commit -m "Add AIT performance metrics for ${{ inputs.wiki-report-desc }} from workflow run ${{ github.run_id }}"
          git push

      - name: Add summary link to workflow
        run: |
          if [ ! -d "all-ait-performance" ] || [ -z "$(ls -A all-ait-performance 2>/dev/null)" ]; then
            echo "## AIT Performance Metrics" >> $GITHUB_STEP_SUMMARY
            echo "No AIT performance files found" >> $GITHUB_STEP_SUMMARY
          else
            # Count total test results across all JSONL files (one test per line)
            TEST_COUNT=0
            for file in all-ait-performance/*-metrics-summary.json; do
              if [ -f "$file" ]; then
                # Count non-empty lines
                COUNT=$(grep -c . "$file" 2>/dev/null || echo 0)
                TEST_COUNT=$((TEST_COUNT + COUNT))
              fi
            done

            echo "## AIT Performance Metrics" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**${TEST_COUNT} test(s)** with metrics reported" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "View detailed metrics in [Wiki - AIT Performance ${{ inputs.wiki-report-desc }}](https://github.com/${{ github.repository }}/wiki/ait-performance-${{ inputs.wiki-report-desc }})" >> $GITHUB_STEP_SUMMARY
          fi

  notify-if-negative-values:
    needs: [ tests ]
    runs-on: ubuntu-22.04
    steps:
      - name: Download artifact(s) # surely there is a way to only download the negative_value_*.txt artifacts?
        uses: actions/download-artifact@65a9edc5881444af0b9093a5e628f2fe47ea3b2e # pin@v4
        env:
          continue-on-error: true
      - name: Send failure message to Slack
        if: ${{ hashFiles('**/negative_value_*.txt') != '' }}
        id: slack
        uses: slackapi/slack-github-action@6c661ce58804a1a20f6dc5fbee7f0381b469e001 # pin@v1.25.0
        with:
          payload: |
            {
              "message": "Negative value detected in AIT run.  Check the artifacts named 'negative_value_*.txt'.  This will tell you which test had the negative value, and the contents will list the events.  And, of course, more details can be found in the logs.",
              "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.NEGATIVE_VALUE_SLACK_WEBHOOK_URL }}
